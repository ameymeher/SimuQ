{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from qiskit_ibm_provider import IBMProvider\n",
    "with open('../ibm_API_key','r') as file:\n",
    "    token = file.readline()\n",
    "\n",
    "provider = IBMProvider(token=token, instance=\"ibm-q-ncsu/nc-state/quantum-compiler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_lines = []\n",
    "for N in range(4,7):\n",
    "    for T in range(1,4):\n",
    "        for noise in range(1,13,2):\n",
    "            data = {'N' : N, 'T':T,'Noise':noise}\n",
    "            data_lines.append(data)\n",
    "\n",
    "df = pd.DataFrame(data_lines)\n",
    "\n",
    "job_ids = [\n",
    "    \"cna13m6m2pvg008sktx0\",\n",
    "    \"cna13nyyzmv0008w8t10\",\n",
    "    \"cna13q6m2pvg008sktxg\",\n",
    "    \"cna13rfj5tjg0080xg9g\",\n",
    "    \"cna13sz1m2c0008wypqg\",\n",
    "    \"cna13v7yzmv0008w8t1g\",\n",
    "    \"cna151m1m2c0008wypxg\",\n",
    "    \"cna152m8ff30008rjhp0\",\n",
    "    \"cna153wj5tjg0080xgcg\",\n",
    "    \"cna155mr0vyg008d7zpg\",\n",
    "    \"cna156wj5tjg0080xgd0\",\n",
    "    \"cna158dyzmv0008w8t20\",\n",
    "    \"cna15wf1m2c0008wypy0\",\n",
    "    \"cna15xzj5tjg0080xgeg\",\n",
    "    \"cna15z7j5tjg0080xgf0\",\n",
    "    \"cna1600r0vyg008d7zqg\",\n",
    "    \"cna16188ff30008rjhsg\",\n",
    "    \"cna162g1m2c0008wypyg\",\n",
    "    \"cna173mr0vyg008d7zrg\",\n",
    "    \"cna174wj5tjg0080xgh0\",\n",
    "    \"cna175wr0vyg008d7zs0\",\n",
    "    \"cna177c8ff30008rjhwg\",\n",
    "    \"cna178x1m2c0008wypzg\",\n",
    "    \"cna17an8ff30008rjhx0\",\n",
    "    \"cna1944m2pvg008skvag\",\n",
    "    \"cna195cr0vyg008d7zx0\",\n",
    "    \"cna196m8ff30008rjj1g\",\n",
    "    \"cna197w8ff30008rjj20\",\n",
    "    \"cna1995r0vyg008d7zxg\",\n",
    "    \"cna19anr0vyg008d7zy0\",\n",
    "    \"cna19t71m2c0008wyq20\",\n",
    "    \"cna19vf1m2c0008wyq2g\",\n",
    "    \"cna19wzj5tjg0080xgp0\",\n",
    "    \"cna19y7j5tjg0080xgpg\",\n",
    "    \"cna19zfyzmv0008w8t6g\",\n",
    "    \"cna1a0r1m2c0008wyq30\",\n",
    "    \"cna1ahaj5tjg0080xgqg\",\n",
    "    \"cna1ajaj5tjg0080xgr0\",\n",
    "    \"cna1akjm2pvg008skvd0\",\n",
    "    \"cna1an2yzmv0008w8t80\",\n",
    "    \"cna1ap28ff30008rjj4g\",\n",
    "    \"cna1apt8ff30008rjj5g\",\n",
    "    \"cna1b34r0vyg008d8010\",\n",
    "    \"cna1b4c1m2c0008wyq4g\",\n",
    "    \"cna1b5w1m2c0008wyq5g\",\n",
    "    \"cna1b74r0vyg008d801g\",\n",
    "    \"cna1b85j5tjg0080xgsg\",\n",
    "    \"cna1b9dr0vyg008d8020\",\n",
    "    \"cna1br7m2pvg008skvh0\",\n",
    "    \"cna1bsf1m2c0008wyq80\",\n",
    "    \"cna1btq8ff30008rjja0\",\n",
    "    \"cna1bvz1m2c0008wyq90\",\n",
    "    \"cna1bwz8ff30008rjjag\",\n",
    "    \"cna1bxz8ff30008rjjb0\"\n",
    "]\n",
    "\n",
    "df['Job Id'] = job_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N  T  Noise                Job Id\n",
      "0   4  1      1  cna13m6m2pvg008sktx0\n",
      "1   4  1      3  cna13nyyzmv0008w8t10\n",
      "2   4  1      5  cna13q6m2pvg008sktxg\n",
      "3   4  1      7  cna13rfj5tjg0080xg9g\n",
      "4   4  1      9  cna13sz1m2c0008wypqg\n",
      "5   4  1     11  cna13v7yzmv0008w8t1g\n",
      "6   4  2      1  cna151m1m2c0008wypxg\n",
      "7   4  2      3  cna152m8ff30008rjhp0\n",
      "8   4  2      5  cna153wj5tjg0080xgcg\n",
      "9   4  2      7  cna155mr0vyg008d7zpg\n",
      "10  4  2      9  cna156wj5tjg0080xgd0\n",
      "11  4  2     11  cna158dyzmv0008w8t20\n",
      "12  4  3      1  cna15wf1m2c0008wypy0\n",
      "13  4  3      3  cna15xzj5tjg0080xgeg\n",
      "14  4  3      5  cna15z7j5tjg0080xgf0\n",
      "15  4  3      7  cna1600r0vyg008d7zqg\n",
      "16  4  3      9  cna16188ff30008rjhsg\n",
      "17  4  3     11  cna162g1m2c0008wypyg\n",
      "18  5  1      1  cna173mr0vyg008d7zrg\n",
      "19  5  1      3  cna174wj5tjg0080xgh0\n",
      "20  5  1      5  cna175wr0vyg008d7zs0\n",
      "21  5  1      7  cna177c8ff30008rjhwg\n",
      "22  5  1      9  cna178x1m2c0008wypzg\n",
      "23  5  1     11  cna17an8ff30008rjhx0\n",
      "24  5  2      1  cna1944m2pvg008skvag\n",
      "25  5  2      3  cna195cr0vyg008d7zx0\n",
      "26  5  2      5  cna196m8ff30008rjj1g\n",
      "27  5  2      7  cna197w8ff30008rjj20\n",
      "28  5  2      9  cna1995r0vyg008d7zxg\n",
      "29  5  2     11  cna19anr0vyg008d7zy0\n",
      "30  5  3      1  cna19t71m2c0008wyq20\n",
      "31  5  3      3  cna19vf1m2c0008wyq2g\n",
      "32  5  3      5  cna19wzj5tjg0080xgp0\n",
      "33  5  3      7  cna19y7j5tjg0080xgpg\n",
      "34  5  3      9  cna19zfyzmv0008w8t6g\n",
      "35  5  3     11  cna1a0r1m2c0008wyq30\n",
      "36  6  1      1  cna1ahaj5tjg0080xgqg\n",
      "37  6  1      3  cna1ajaj5tjg0080xgr0\n",
      "38  6  1      5  cna1akjm2pvg008skvd0\n",
      "39  6  1      7  cna1an2yzmv0008w8t80\n",
      "40  6  1      9  cna1ap28ff30008rjj4g\n",
      "41  6  1     11  cna1apt8ff30008rjj5g\n",
      "42  6  2      1  cna1b34r0vyg008d8010\n",
      "43  6  2      3  cna1b4c1m2c0008wyq4g\n",
      "44  6  2      5  cna1b5w1m2c0008wyq5g\n",
      "45  6  2      7  cna1b74r0vyg008d801g\n",
      "46  6  2      9  cna1b85j5tjg0080xgsg\n",
      "47  6  2     11  cna1b9dr0vyg008d8020\n",
      "48  6  3      1  cna1br7m2pvg008skvh0\n",
      "49  6  3      3  cna1bsf1m2c0008wyq80\n",
      "50  6  3      5  cna1btq8ff30008rjja0\n",
      "51  6  3      7  cna1bvz1m2c0008wyq90\n",
      "52  6  3      9  cna1bwz8ff30008rjjag\n",
      "53  6  3     11  cna1bxz8ff30008rjjb0\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df['raw_result'] = df['Job Id'].apply(lambda x: provider.retrieve_job(x).result().get_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_average_distributions(same_circuit_results):\n",
    "\n",
    "    all_keys = set()\n",
    "    for dist in same_circuit_results:\n",
    "        all_keys = all_keys.union(set(dist.keys()))\n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    def default_value():\n",
    "        return 0\n",
    "\n",
    "    average_dist = defaultdict(default_value)\n",
    "\n",
    "    for key in all_keys:\n",
    "        for i in range(len(same_circuit_results)):\n",
    "            if key in same_circuit_results[i]:\n",
    "                average_dist[key] =  average_dist[key] + same_circuit_results[i][key]\n",
    "\n",
    "        average_dist[key] = average_dist[key] // len(same_circuit_results)\n",
    "\n",
    "    return average_dist\n",
    "\n",
    "df['average_result'] = df['raw_result'].apply(lambda x: get_average_distributions(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def process_results(result,layout):\n",
    "\n",
    "    def layout_rev(res):\n",
    "        n = len(layout)\n",
    "        # print(self.layout)\n",
    "        b = res\n",
    "        ret = \"\"\n",
    "        for i in range(n):\n",
    "            ret += b[-1 - layout[i]]\n",
    "        return ret\n",
    "\n",
    "\n",
    "    n_shots = sum(result.values())\n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    def default_value():\n",
    "        return 0\n",
    "\n",
    "    ret = defaultdict(default_value)\n",
    "\n",
    "    for key in result.keys():\n",
    "        new_key = layout_rev(key)\n",
    "        ret[new_key] += result[key] / n_shots\n",
    "\n",
    "    return ret\n",
    "\n",
    "def get_layout(row):\n",
    "    layout = None\n",
    "    if row['N'] == 4:\n",
    "        layout = [0,1,2,3]\n",
    "    elif row['N'] == 5:\n",
    "        layout = [0,1,2,3,5]\n",
    "    else:\n",
    "        layout = [0,1,2,3,5,8]\n",
    "\n",
    "    return process_results(row['average_result'],layout)\n",
    "\n",
    "df['processed_result'] = df.apply(lambda x: get_layout(x), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n",
      "Compiled.\n",
      "Solved.\n"
     ]
    }
   ],
   "source": [
    "#Getting the ideal results\n",
    "from SimuQ.thesis.Experiment.utilities.hamiltonian_models import Ising\n",
    "from simuq.qutip import QuTiPProvider\n",
    "import numpy as np\n",
    "\n",
    "def get_ideal_result(N,T):\n",
    "    #Ising chain model creation\n",
    "    h = np.array([1 for j in range(N)])\n",
    "    J_chain = np.zeros((N, N))\n",
    "    for j in range(N - 1):\n",
    "        J_chain[j, j + 1] = 1\n",
    "\n",
    "    J_cycle = np.copy(J_chain)\n",
    "    J_cycle[0, N - 1] = 1\n",
    "    Ising_chain = Ising(N, T, J_chain, h)\n",
    "\n",
    "    #Classical simulation\n",
    "    qtpp = QuTiPProvider()\n",
    "    qtpp.compile(Ising_chain)\n",
    "    qtpp.run()\n",
    "\n",
    "    return qtpp.results()\n",
    "\n",
    "df['ideal_result'] = df.apply(lambda x: get_ideal_result(x['N'],x['T']), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from qiskit.quantum_info import hellinger_fidelity\n",
    "from SimuQ.thesis.Experiment.utilities.evaluation_metrics import TV\n",
    "\n",
    "df['Hellinger fidelity'] = df.apply(lambda x: hellinger_fidelity(x['ideal_result'],x['processed_result']), axis=1)\n",
    "df['Total Variational Distance'] = df.apply(lambda x: TV(x['ideal_result'],x['processed_result']), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N  T  Noise  Hellinger fidelity  Total Variational Distance\n",
      "0   4  1      1            0.928722                    0.186743\n",
      "1   4  1      3            0.769959                    0.351347\n",
      "2   4  1      5            0.776780                    0.375950\n",
      "3   4  1      7            0.695552                    0.439344\n",
      "4   4  1      9            0.675728                    0.442812\n",
      "5   4  1     11            0.764835                    0.342631\n",
      "6   4  2      1            0.860347                    0.291313\n",
      "7   4  2      3            0.736569                    0.419337\n",
      "8   4  2      5            0.725219                    0.422130\n",
      "9   4  2      7            0.700404                    0.457199\n",
      "10  4  2      9            0.689274                    0.470114\n",
      "11  4  2     11            0.692479                    0.465068\n",
      "12  4  3      1            0.663586                    0.496030\n",
      "13  4  3      3            0.655878                    0.518363\n",
      "14  4  3      5            0.664281                    0.477369\n",
      "15  4  3      7            0.680299                    0.452885\n",
      "16  4  3      9            0.721203                    0.410357\n",
      "17  4  3     11            0.743397                    0.405188\n",
      "18  5  1      1            0.900929                    0.247188\n",
      "19  5  1      3            0.776309                    0.375102\n",
      "20  5  1      5            0.680558                    0.471580\n",
      "21  5  1      7            0.602430                    0.544326\n",
      "22  5  1      9            0.641346                    0.502366\n",
      "23  5  1     11            0.709646                    0.430503\n",
      "24  5  2      1            0.820804                    0.315448\n",
      "25  5  2      3            0.681412                    0.457293\n",
      "26  5  2      5            0.609573                    0.531245\n",
      "27  5  2      7            0.519247                    0.618691\n",
      "28  5  2      9            0.555812                    0.583681\n",
      "29  5  2     11            0.587431                    0.530418\n",
      "30  5  3      1            0.196954                    0.824929\n",
      "31  5  3      3            0.243367                    0.793268\n",
      "32  5  3      5            0.234985                    0.800470\n",
      "33  5  3      7            0.254537                    0.789777\n",
      "34  5  3      9            0.257892                    0.804955\n",
      "35  5  3     11            0.261213                    0.788408\n",
      "36  6  1      1            0.871577                    0.274199\n",
      "37  6  1      3            0.719384                    0.438579\n",
      "38  6  1      5            0.607259                    0.521087\n",
      "39  6  1      7            0.469164                    0.641023\n",
      "40  6  1      9            0.514969                    0.594257\n",
      "41  6  1     11            0.583007                    0.524206\n",
      "42  6  2      1            0.724343                    0.426466\n",
      "43  6  2      3            0.663097                    0.484194\n",
      "44  6  2      5            0.538331                    0.582573\n",
      "45  6  2      7            0.563622                    0.563203\n",
      "46  6  2      9            0.526160                    0.583860\n",
      "47  6  2     11            0.569900                    0.542634\n",
      "48  6  3      1            0.608091                    0.508490\n",
      "49  6  3      3            0.520097                    0.600296\n",
      "50  6  3      5            0.469007                    0.627729\n",
      "51  6  3      7            0.465874                    0.608641\n",
      "52  6  3      9            0.491100                    0.591727\n",
      "53  6  3     11            0.495239                    0.581605\n"
     ]
    }
   ],
   "source": [
    "print(df[['N','T','Noise','Hellinger fidelity','Total Variational Distance']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['N', 'T', 'Noise', 'Job Id', 'raw_result', 'average_result',\n",
      "       'processed_result', 'ideal_result', 'Hellinger fidelity',\n",
      "       'Total Variational Distance', 'Top 10 ideal dist'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df['Top 10 ideal dist'] = df['ideal_result'].apply(lambda x: dict(sorted(x.items(), key= lambda y: y[1], reverse=True)[:10]))\n",
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def filter_dist(row):\n",
    "    ideal_dist_keys = list(row['Top 10 ideal dist'].keys())\n",
    "    dist = row['processed_result']\n",
    "\n",
    "    top_10_expected_dist = {}\n",
    "    for key in ideal_dist_keys:\n",
    "        top_10_expected_dist[key] = dist[key]\n",
    "\n",
    "    return top_10_expected_dist\n",
    "\n",
    "df['Top 10 expected dist'] = df.apply(lambda x: filter_dist(x),axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "zne_dfs = []\n",
    "\n",
    "for N in range(4,7):\n",
    "    for T in range(1,4):\n",
    "        ideal_dist = df[(df['N'] == N) & (df['T'] == T) & (df['Noise'] == 1)]['Top 10 ideal dist'].iat[0]\n",
    "        keys = list(ideal_dist.keys())\n",
    "\n",
    "        def append_noise_data(row):\n",
    "            new_dict = {'Noise' : row['Noise']}\n",
    "            new_dict.update(row['Top 10 expected dist'])\n",
    "            row['Top 10 expected dist'] = new_dict\n",
    "            return row\n",
    "\n",
    "        ideal_data = {'Noise' : 0}\n",
    "        ideal_data.update(ideal_dist)\n",
    "        zne_df_data = [ideal_data]\n",
    "\n",
    "        zne_df_data = zne_df_data + list(df[(df['N'] == N) & (df['T'] == T)][['Noise','Top 10 expected dist']].apply(lambda x: append_noise_data(x), axis=1)['Top 10 expected dist'])\n",
    "        zne_df = pd.DataFrame(zne_df_data)\n",
    "\n",
    "        zne_dfs.append(zne_df)\n",
    "\n",
    "number_of_points = 4\n",
    "df_id = 0\n",
    "degree = 1\n",
    "\n",
    "def normalize(distA, distB):\n",
    "    total_A_sum = 1 - sum(distA.values())\n",
    "    total_B_sum = 0\n",
    "\n",
    "    for key in distA:\n",
    "        total_B_sum += distB[key]\n",
    "\n",
    "    total_B_sum = 1 - total_B_sum\n",
    "\n",
    "    distC = {}\n",
    "    for key in distB:\n",
    "        if key in distA:\n",
    "            distC[key] = distA[key]\n",
    "        else:\n",
    "            distC[key] = distB[key] * total_A_sum / total_B_sum\n",
    "\n",
    "    return distC\n",
    "\n",
    "def extrapolate(col,x_points):\n",
    "    if col.name == 'Noise':\n",
    "        temp = pd.Series(['ZNE mitigated probability'])\n",
    "    else:\n",
    "        y = list(col)\n",
    "        coefficients = np.polyfit(x_points, y, degree)\n",
    "        poly_function = np.poly1d(coefficients)\n",
    "        predicted_y_value = 0 if poly_function(0) < 0 else poly_function(0)     #Need to confirm with Professor\n",
    "        temp = pd.Series([predicted_y_value])\n",
    "    return temp\n",
    "\n",
    "zne_mitigated_df_list = []\n",
    "\n",
    "for N in range(4,7):\n",
    "    for T in range(1,4):\n",
    "\n",
    "        x_points = np.array([i for i in range(1,number_of_points * 2,2)])\n",
    "\n",
    "        y_df = zne_dfs[df_id][1:number_of_points + 1]\n",
    "        y_df_mitigated = y_df.apply(lambda x: extrapolate(x,x_points), axis=0)\n",
    "\n",
    "        zne_dfs[df_id] = pd.concat([zne_dfs[df_id],y_df_mitigated],axis=0,ignore_index=True)\n",
    "        record = y_df_mitigated.to_dict(orient='records')[0]\n",
    "\n",
    "        record.pop('Noise',None)\n",
    "\n",
    "        ideal_dist = df[(df['N'] == N) & (df['T'] == T) & (df['Noise'] == 1)]['ideal_result'].iat[0]\n",
    "        dist = normalize(record,ideal_dist)\n",
    "\n",
    "        zne_mitigated_data = {\n",
    "            'N': N,\n",
    "            'T':T,\n",
    "            'Mitigated Distribution': dist,\n",
    "            'Ideal Distribution' : ideal_dist,\n",
    "            'Hellinger fidelity' : hellinger_fidelity(dist, ideal_dist),\n",
    "            'Initial Hellinger fidelity' : df[(df['N'] == N) & (df['T'] == T) & (df['Noise'] == 1)]['Hellinger fidelity'].iat[0],\n",
    "            'Total variational distance' : TV(dist,ideal_dist),\n",
    "            'Initial Total Variational distance' : df[(df['N'] == N) & (df['T'] == T) & (df['Noise'] == 1)]['Total Variational Distance'].iat[0]}\n",
    "\n",
    "        zne_mitigated_df_list.append(zne_mitigated_data)\n",
    "        df_id += 1\n",
    "\n",
    "zne_mitigated_df = pd.DataFrame(zne_mitigated_df_list)\n",
    "\n",
    "with pd.ExcelWriter('top_10_probabilities.xlsx',engine='xlsxwriter') as writer:\n",
    "    count = 0\n",
    "    for N in range(4,7):\n",
    "        for T in range(1,4):\n",
    "            zne_dfs[count].to_excel(writer,sheet_name='N_{}_T_{}'.format(N,T),index=False)\n",
    "            count += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "   N  T                             Mitigated Distribution  \\\n0  4  1  {'0000': 0.1778245674619108, '0001': 0.0520480...   \n1  4  2  {'0000': 0.08705373070311322, '0001': 0.065093...   \n2  4  3  {'0000': 0.047423864372826086, '0001': 0.07761...   \n3  5  1  {'00000': 0.06441866318119739, '00001': 0.0890...   \n4  5  2  {'00000': 0.07331711873592966, '00001': 0.0283...   \n5  5  3  {'00000': 0.008177090601991129, '00001': 0.010...   \n6  6  1  {'000000': 0.0718545645400407, '000001': 0.037...   \n7  6  2  {'000000': 0.013408353432121104, '000001': 0.0...   \n8  6  3  {'000000': 0.016317222853242504, '000001': 0.0...   \n\n                                  Ideal Distribution  Hellinger fidelity  \\\n0  {'0000': 0.21072942962058566, '0001': 0.109919...            0.966814   \n1  {'0000': 0.2770214655429199, '0001': 0.0598548...            0.841930   \n2  {'0000': 0.24648402578991985, '0001': 0.018513...            0.651050   \n3  {'00000': 0.16859825082132646, '00001': 0.0980...            0.932765   \n4  {'00000': 0.03419323155440778, '00001': 0.0796...            0.910306   \n5  {'00000': 0.39208989435406016, '00001': 0.0142...            0.231704   \n6  {'000000': 0.13909131418319828, '000001': 0.07...            0.939279   \n7  {'000000': 0.058408399848135006, '000001': 0.0...            0.884796   \n8  {'000000': 0.2216031757421513, '000001': 0.028...            0.734320   \n\n   Initial Hellinger fidelity  Total variational distance  \\\n0                    0.928722                    0.149512   \n1                    0.860347                    0.305844   \n2                    0.663586                    0.519089   \n3                    0.900929                    0.212680   \n4                    0.820804                    0.278310   \n5                    0.196954                    0.825781   \n6                    0.871577                    0.220197   \n7                    0.724343                    0.308069   \n8                    0.608091                    0.462087   \n\n   Initial Total Variational distance  \n0                            0.186743  \n1                            0.291313  \n2                            0.496030  \n3                            0.247188  \n4                            0.315448  \n5                            0.824929  \n6                            0.274199  \n7                            0.426466  \n8                            0.508490  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>N</th>\n      <th>T</th>\n      <th>Mitigated Distribution</th>\n      <th>Ideal Distribution</th>\n      <th>Hellinger fidelity</th>\n      <th>Initial Hellinger fidelity</th>\n      <th>Total variational distance</th>\n      <th>Initial Total Variational distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>1</td>\n      <td>{'0000': 0.1778245674619108, '0001': 0.0520480...</td>\n      <td>{'0000': 0.21072942962058566, '0001': 0.109919...</td>\n      <td>0.966814</td>\n      <td>0.928722</td>\n      <td>0.149512</td>\n      <td>0.186743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>2</td>\n      <td>{'0000': 0.08705373070311322, '0001': 0.065093...</td>\n      <td>{'0000': 0.2770214655429199, '0001': 0.0598548...</td>\n      <td>0.841930</td>\n      <td>0.860347</td>\n      <td>0.305844</td>\n      <td>0.291313</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>3</td>\n      <td>{'0000': 0.047423864372826086, '0001': 0.07761...</td>\n      <td>{'0000': 0.24648402578991985, '0001': 0.018513...</td>\n      <td>0.651050</td>\n      <td>0.663586</td>\n      <td>0.519089</td>\n      <td>0.496030</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>1</td>\n      <td>{'00000': 0.06441866318119739, '00001': 0.0890...</td>\n      <td>{'00000': 0.16859825082132646, '00001': 0.0980...</td>\n      <td>0.932765</td>\n      <td>0.900929</td>\n      <td>0.212680</td>\n      <td>0.247188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2</td>\n      <td>{'00000': 0.07331711873592966, '00001': 0.0283...</td>\n      <td>{'00000': 0.03419323155440778, '00001': 0.0796...</td>\n      <td>0.910306</td>\n      <td>0.820804</td>\n      <td>0.278310</td>\n      <td>0.315448</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>3</td>\n      <td>{'00000': 0.008177090601991129, '00001': 0.010...</td>\n      <td>{'00000': 0.39208989435406016, '00001': 0.0142...</td>\n      <td>0.231704</td>\n      <td>0.196954</td>\n      <td>0.825781</td>\n      <td>0.824929</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>1</td>\n      <td>{'000000': 0.0718545645400407, '000001': 0.037...</td>\n      <td>{'000000': 0.13909131418319828, '000001': 0.07...</td>\n      <td>0.939279</td>\n      <td>0.871577</td>\n      <td>0.220197</td>\n      <td>0.274199</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>2</td>\n      <td>{'000000': 0.013408353432121104, '000001': 0.0...</td>\n      <td>{'000000': 0.058408399848135006, '000001': 0.0...</td>\n      <td>0.884796</td>\n      <td>0.724343</td>\n      <td>0.308069</td>\n      <td>0.426466</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>6</td>\n      <td>3</td>\n      <td>{'000000': 0.016317222853242504, '000001': 0.0...</td>\n      <td>{'000000': 0.2216031757421513, '000001': 0.028...</td>\n      <td>0.734320</td>\n      <td>0.608091</td>\n      <td>0.462087</td>\n      <td>0.508490</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zne_mitigated_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "temp_dfs = []\n",
    "\n",
    "for N in range(4,7):\n",
    "    for T in range(1,4):\n",
    "        dist = zne_mitigated_df[(zne_mitigated_df['N'] == N) & (zne_mitigated_df['T'] == T)]['Mitigated Distribution'].iat[0]\n",
    "        ideal_dist = zne_mitigated_df[(zne_mitigated_df['N'] == N) & (zne_mitigated_df['T'] == T)]['Ideal Distribution'].iat[0]\n",
    "\n",
    "        temp_df = pd.DataFrame([dist,ideal_dist])\n",
    "        temp_dfs.append(temp_df)\n",
    "\n",
    "with pd.ExcelWriter('zne_results.xlsx',engine='xlsxwriter') as writer:\n",
    "    count = 0\n",
    "    zne_mitigated_df.to_excel(writer,sheet_name='zne_results',index=False)\n",
    "    for N in range(4,7):\n",
    "        for T in range(1,4):\n",
    "            temp_dfs[count].to_excel(writer,sheet_name='N_{}_T_{}'.format(N,T),index=False)\n",
    "            count += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
