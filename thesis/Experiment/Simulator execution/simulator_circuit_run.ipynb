{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from qiskit_ibm_provider import IBMProvider\n",
    "import pandas as pd\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "import qiskit_aer.noise as noise\n",
    "from qiskit.quantum_info import hellinger_fidelity\n",
    "from evaluation_metrics import TV\n",
    "import numpy as np\n",
    "from math import pow\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl.styles import Border, Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_file = \"../../ibm_API_key\"\n",
    "with open(api_file, \"r\") as f:\n",
    "    api_key = f.readline().strip()\n",
    "provider = IBMProvider(api_key, instance='ibm-q-ncsu/nc-state/quantum-compiler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ideal_results.pkl', 'rb') as f:\n",
    "    ideal_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(circ, backend, with_noise):\n",
    "    if with_noise:\n",
    "        # load noise model\n",
    "        with open(f'noise_models/{backend.name}_noise_model.pkl', 'rb') as f:\n",
    "            noise_model = pickle.load(f)\n",
    "\n",
    "        # create a simulator for backend with noise model\n",
    "        basis_gates = noise_model.basis_gates\n",
    "        coupling_map = backend.configuration().coupling_map\n",
    "\n",
    "        sim = AerSimulator(noise_model=noise_model,\n",
    "                        basis_gates=basis_gates,\n",
    "                        coupling_map=coupling_map)\n",
    "    else:\n",
    "        # create a simulator for backend\n",
    "        sim = AerSimulator()\n",
    "\n",
    "    # simulate and extract results\n",
    "    shots = 4096\n",
    "    simulator_result = sim.run(circ, shots = shots, seed_simulator=12345).result()\n",
    "    simulator_counts = simulator_result.get_counts()\n",
    "\n",
    "    #Reverse the key strings\n",
    "    simulator_counts = {k[::-1]: v/shots for k, v in simulator_counts.items()}\n",
    "\n",
    "    return simulator_counts\n",
    "\n",
    "#ZNE function\n",
    "def zne(dists,degree, number_of_points, top=65,percentage_mode=False):\n",
    "\n",
    "    if percentage_mode:\n",
    "        number_of_keys = (len(dists[0].keys()) * top) // 100\n",
    "    else:\n",
    "        number_of_keys = top\n",
    "\n",
    "    #Getting the top 10 results from the distribution\n",
    "    sorted_dist = dict(sorted(dists[0].items(), key=lambda x: x[1], reverse=True))\n",
    "    top_k = list(sorted_dist.keys())[:number_of_keys]\n",
    "    remaining_keys = list(sorted_dist.keys())[number_of_keys:]\n",
    "\n",
    "    #Since this was global folding\n",
    "    x_axis = np.array([i for i in range(1,number_of_points * 2,2)])\n",
    "\n",
    "    #Extrapolation of top 10 results\n",
    "    mitigated_top_k_dist = {}\n",
    "\n",
    "    for key in top_k:\n",
    "        mitigated_top_k_dist[key] = 0\n",
    "        y_axis = np.array([ dists[i][key] if key in dists[i] else 0 for i in range(0,number_of_points)])\n",
    "        coefficients = np.polyfit(x_axis, y_axis, degree)\n",
    "        poly = np.poly1d(coefficients)\n",
    "        mitigated_top_k_dist[key] = 0 if poly(0) < 0 else poly(0)\n",
    "\n",
    "    #Calculate the sum of the mitigated top 10 distribution\n",
    "    sum_mitigated_top_k_dist = sum(mitigated_top_k_dist.values())\n",
    "    from functools import reduce\n",
    "    sum_remaining_keys = reduce(lambda acc, key_value: acc + key_value[1] if key_value[0] in remaining_keys else acc, sorted_dist.items(), 0)\n",
    "    total_sum = sum_mitigated_top_k_dist + sum_remaining_keys\n",
    "\n",
    "    #Normalize the mitigated top 10 distribution\n",
    "    normalized_mitigated_top_k_dist = dict(map(lambda x: (x[0],x[1]/total_sum),mitigated_top_k_dist.items()))\n",
    "    normalized_mitigated_top_k_dist.update(dict(map(lambda x: (x[0],x[1]/total_sum),list(filter(lambda x: x[0] in remaining_keys,sorted_dist.items())))))\n",
    "    return normalized_mitigated_top_k_dist\n",
    "\n",
    "#Function for performing folding free ZNE\n",
    "def folding_free_zne(dist,reliability,N,top=65,percentage_mode=False):\n",
    "\n",
    "    if percentage_mode:\n",
    "        number_of_keys = (len(dist.keys()) * top) // 100\n",
    "    else:\n",
    "        number_of_keys = top\n",
    "\n",
    "    #Getting the top 10 results from the distribution\n",
    "    sorted_dist = dict(sorted(dist.items(), key=lambda x: x[1], reverse=True))\n",
    "    top_k = list(sorted_dist.keys())[:number_of_keys]\n",
    "    remaining_keys = list(sorted_dist.keys())[number_of_keys:]\n",
    "\n",
    "    x_axis = [(1-reliability),1]\n",
    "\n",
    "    #Extrapolation of top k results\n",
    "    mitigated_top_k_dist = {}\n",
    "\n",
    "    for key in top_k:\n",
    "        mitigated_top_k_dist[key] = 0\n",
    "        y_axis = [dist[key] if key in dist else 0,pow(2,-N)]\n",
    "        coefficients = np.polyfit(x_axis, y_axis, 1)\n",
    "        poly = np.poly1d(coefficients)\n",
    "        mitigated_top_k_dist[key] = 0 if poly(0) < 0 else poly(0)\n",
    "\n",
    "    #Calculate the sum of the mitigated top 10 distribution\n",
    "    sum_mitigated_top_k_dist = sum(mitigated_top_k_dist.values())\n",
    "    from functools import reduce\n",
    "    sum_remaining_keys = reduce(lambda acc, key_value: acc + key_value[1] if key_value[0] in remaining_keys else acc, sorted_dist.items(), 0)\n",
    "    total_sum = sum_mitigated_top_k_dist + sum_remaining_keys\n",
    "\n",
    "    #Normalize the mitigated top 10 distribution\n",
    "    normalized_mitigated_top_k_dist = dict(map(lambda x: (x[0],x[1]/total_sum),mitigated_top_k_dist.items()))\n",
    "    normalized_mitigated_top_k_dist.update(dict(map(lambda x: (x[0],x[1]/total_sum),list(filter(lambda x: x[0] in remaining_keys,sorted_dist.items())))))\n",
    "\n",
    "    return normalized_mitigated_top_k_dist\n",
    "\n",
    "#Function for performing reliability based ZNE\n",
    "def reliability_based_zne(dists,N,reliabilities,number_of_points,top=65,percentage_mode=False):\n",
    "\n",
    "    if percentage_mode:\n",
    "        number_of_keys = (len(dists[0].keys()) * top) // 100\n",
    "    else:\n",
    "        number_of_keys = top\n",
    "\n",
    "    #Getting the top 10 results from the distribution\n",
    "    sorted_dist = dict(sorted(dists[0].items(), key=lambda x: x[1], reverse=True))\n",
    "    top_k = list(sorted_dist.keys())[:number_of_keys]\n",
    "    remaining_keys = list(sorted_dist.keys())[number_of_keys:]\n",
    "\n",
    "    x_axis = list(map(lambda x: 1-x, reliabilities))\n",
    "    #x_axis = x_axis[:number_of_points] + [1]\n",
    "    x_axis = x_axis[:number_of_points]\n",
    "    \n",
    "    #Extrapolation of top 10 results\n",
    "    mitigated_top_k_dist = {}\n",
    "\n",
    "    for key in top_k:\n",
    "        mitigated_top_k_dist[key] = 0\n",
    "        #y_axis = np.array([dists[i][key] if key in dists[i] else 0 for i in range(0,number_of_points)] + [pow(2,-N)]) \n",
    "        y_axis = np.array([dists[i][key] if key in dists[i] else 0 for i in range(0,number_of_points)])\n",
    "        coefficients = np.polyfit(x_axis, y_axis, 1)\n",
    "        poly = np.poly1d(coefficients)\n",
    "        mitigated_top_k_dist[key] = 0 if poly(0) < 0 else poly(0)\n",
    "\n",
    "    #Calculate the sum of the mitigated top 10 distribution\n",
    "    sum_mitigated_top_k_dist = sum(mitigated_top_k_dist.values())\n",
    "    from functools import reduce\n",
    "    sum_remaining_keys = reduce(lambda acc, key_value: acc + key_value[1] if key_value[0] in remaining_keys else acc, sorted_dist.items(), 0)\n",
    "    total_sum = sum_mitigated_top_k_dist + sum_remaining_keys\n",
    "\n",
    "    #Normalize the mitigated top 10 distribution\n",
    "    normalized_mitigated_top_10_dist = dict(map(lambda x: (x[0],x[1]/total_sum),mitigated_top_k_dist.items()))\n",
    "    normalized_mitigated_top_10_dist.update(dict(map(lambda x: (x[0],x[1]/total_sum),list(filter(lambda x: x[0] in remaining_keys,sorted_dist.items())))))\n",
    "\n",
    "    return normalized_mitigated_top_10_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29064\\780643242.py:86: RankWarning: Polyfit may be poorly conditioned\n",
      "  coefficients = np.polyfit(x_axis, y_axis, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ibm_brisbane N=4 T=1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m ideal_result \u001b[38;5;241m=\u001b[39m ideal_results[N,T]\n\u001b[0;32m     23\u001b[0m without_noise_simulation_result \u001b[38;5;241m=\u001b[39m simulate(circuits[\u001b[38;5;241m0\u001b[39m], backend, with_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m noise_simulation_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate the Hellinger fidelity\u001b[39;00m\n\u001b[0;32m     27\u001b[0m without_noise_simulation_hf \u001b[38;5;241m=\u001b[39m hellinger_fidelity(ideal_result, without_noise_simulation_result)\n",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(circ)\u001b[0m\n\u001b[0;32m     22\u001b[0m ideal_result \u001b[38;5;241m=\u001b[39m ideal_results[N,T]\n\u001b[0;32m     23\u001b[0m without_noise_simulation_result \u001b[38;5;241m=\u001b[39m simulate(circuits[\u001b[38;5;241m0\u001b[39m], backend, with_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m noise_simulation_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m circ: \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, circuits))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate the Hellinger fidelity\u001b[39;00m\n\u001b[0;32m     27\u001b[0m without_noise_simulation_hf \u001b[38;5;241m=\u001b[39m hellinger_fidelity(ideal_result, without_noise_simulation_result)\n",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m, in \u001b[0;36msimulate\u001b[1;34m(circ, backend, with_noise)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_noise:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# load noise model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_noise_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 5\u001b[0m         noise_model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# create a simulator for backend with noise model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     basis_gates \u001b[38;5;241m=\u001b[39m noise_model\u001b[38;5;241m.\u001b[39mbasis_gates\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\simuq2\\Lib\\site-packages\\qiskit\\circuit\\bit.py:68\u001b[0m, in \u001b[0;36mBit.__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repr\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hash\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summary_dict_list = []\n",
    "\n",
    "for system in ['ibm_brisbane','ibm_kyoto','ibm_sherbrooke','ibm_nazca']:\n",
    "\n",
    "    backend = provider.get_backend(system)\n",
    "\n",
    "    for N in [4,6,8,10]:\n",
    "        for T in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.5,2.0]:\n",
    "\n",
    "            print(f'Processing {system} N={N} T={T}')\n",
    "\n",
    "            # Load the circuit data\n",
    "            with open(f'circuits/{system}_{N}_{str(T).replace('.','-')}.pkl', 'rb') as f:\n",
    "                circuit_data = pickle.load(f)\n",
    "\n",
    "            # Get the circuit data\n",
    "            layout = circuit_data['layout']\n",
    "            circuits = circuit_data['circuit']\n",
    "            reliabilities = circuit_data['circuit_reliabilities']\n",
    "\n",
    "            # Get the simulation distributions\n",
    "            ideal_result = ideal_results[N,T]\n",
    "            without_noise_simulation_result = simulate(circuits[0], backend, with_noise=False)\n",
    "            noise_simulation_result = list(map(lambda circ: simulate(circ, backend, with_noise=True), circuits))\n",
    "\n",
    "            # Calculate the Hellinger fidelity\n",
    "            without_noise_simulation_hf = hellinger_fidelity(ideal_result, without_noise_simulation_result)\n",
    "            noise_simulation_hf = list(map(lambda result: hellinger_fidelity(ideal_result, result), noise_simulation_result))\n",
    "\n",
    "            # Calculate the TV distance\n",
    "            without_noise_simulation_tv = TV(ideal_result, without_noise_simulation_result)\n",
    "            noise_simulation_tv = list(map(lambda result: TV(ideal_result, result), noise_simulation_result))\n",
    "\n",
    "            # Get the complete set of keys\n",
    "            keys = set(ideal_result.keys()) | \\\n",
    "                    set(without_noise_simulation_result.keys()) | \\\n",
    "                    set(noise_simulation_result[0].keys()) | \\\n",
    "                    set(noise_simulation_result[1].keys()) | \\\n",
    "                    set(noise_simulation_result[2].keys()) | \\\n",
    "                    set(noise_simulation_result[3].keys()) | \\\n",
    "                    set(noise_simulation_result[4].keys())\n",
    "\n",
    "            keys = sorted(list(keys))\n",
    "\n",
    "            #Create a df and assign keys as index and name the column as State and add the values of keys to that column\n",
    "            distribution_data_df = pd.DataFrame(keys,columns=['State'],index=keys)\n",
    "\n",
    "            #map the results to the distribution data\n",
    "            distribution_data_df['Ideal distribution'] = distribution_data_df['State'].map(ideal_result)\n",
    "            distribution_data_df['Without Noise Distribution'] = distribution_data_df['State'].map(without_noise_simulation_result)\n",
    "            distribution_data_df['Noise Distribution (Factor 1)'] = distribution_data_df['State'].map(noise_simulation_result[0])\n",
    "            distribution_data_df['Noise Distribution (Factor 3)'] = distribution_data_df['State'].map(noise_simulation_result[1])\n",
    "            distribution_data_df['Noise Distribution (Factor 5)'] = distribution_data_df['State'].map(noise_simulation_result[2])\n",
    "            distribution_data_df['Noise Distribution (Factor 7)'] = distribution_data_df['State'].map(noise_simulation_result[3])\n",
    "            distribution_data_df['Noise Distribution (Factor 9)'] = distribution_data_df['State'].map(noise_simulation_result[4])\n",
    "\n",
    "            #ZNE\n",
    "            zne_results = zne(noise_simulation_result,2,3,10)\n",
    "            zne_hf = hellinger_fidelity(ideal_result, zne_results)\n",
    "            zne_tv = TV(ideal_result, zne_results)\n",
    "            distribution_data_df['ZNE distribution'] = distribution_data_df['State'].map(zne_results)\n",
    "\n",
    "            #FFZNE\n",
    "            ffzne_results = folding_free_zne(noise_simulation_result[0],reliabilities[0],N,10)\n",
    "            ffzne_hf = hellinger_fidelity(ideal_result, ffzne_results)\n",
    "            ffzne_tv = TV(ideal_result, ffzne_results)\n",
    "            distribution_data_df['FFZNE distribution'] = distribution_data_df['State'].map(ffzne_results)\n",
    "\n",
    "            #RBZNE\n",
    "            rbzne_results = reliability_based_zne(noise_simulation_result,N,reliabilities,3,10)\n",
    "            rbzne_hf = hellinger_fidelity(ideal_result, rbzne_results)\n",
    "            rbzne_tv = TV(ideal_result, rbzne_results)\n",
    "            distribution_data_df['RBZNE distribution'] = distribution_data_df['State'].map(rbzne_results)\n",
    "\n",
    "            #Sort based on Simulation probability\n",
    "            distribution_data_df = distribution_data_df.sort_values(by='Ideal distribution',ascending=False)\n",
    "\n",
    "            summary_dict_list.append({  'N': N,\n",
    "                                        'T': T,\n",
    "                                        'System': system,\n",
    "                                        'Without Noise HF': without_noise_simulation_hf,\n",
    "                                        'Without Noise TV': without_noise_simulation_tv,\n",
    "                                        'Noise HF': noise_simulation_hf[0],\n",
    "                                        'Noise TV': noise_simulation_tv[0],\n",
    "                                        'ZNE HF': zne_hf,\n",
    "                                        'ZNE TV': zne_tv,\n",
    "                                        'FFZNE HF': ffzne_hf,\n",
    "                                        'FFZNE TV': ffzne_tv,\n",
    "                                        'RBZNE HF': rbzne_hf,\n",
    "                                        'RBZNE TV': rbzne_tv\n",
    "                                    })\n",
    "\n",
    "            counter = int(pow(2,N) + 3)\n",
    "            sheet_name = 'N_{}_T_{}'.format(N,T)\n",
    "\n",
    "            #write in append mode\n",
    "            with pd.ExcelWriter(\"results/{}_distribution_data.xlsx\".format(system),mode='a', engine='openpyxl') as writer:\n",
    "                distribution_data_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                workbook = writer.book\n",
    "                worksheet = writer.sheets[sheet_name]\n",
    "                \n",
    "                # Accessing the active sheet\n",
    "                active_sheet = workbook.active\n",
    "                \n",
    "                # Write to cell A19\n",
    "                worksheet['A{}'.format(str(counter))] = 'Hellinger fidelity'\n",
    "                worksheet['A{}'.format(str(counter+1))] = 'TV'\n",
    "                worksheet['C{}'.format(str(counter))] = without_noise_simulation_hf\n",
    "                worksheet['C{}'.format(str(counter+1))] = without_noise_simulation_tv\n",
    "                worksheet['D{}'.format(str(counter))] = noise_simulation_hf[0]\n",
    "                worksheet['D{}'.format(str(counter+1))] = noise_simulation_tv[0]\n",
    "                worksheet['E{}'.format(str(counter))] = noise_simulation_hf[1]\n",
    "                worksheet['E{}'.format(str(counter+1))] = noise_simulation_tv[1]\n",
    "                worksheet['F{}'.format(str(counter))] = noise_simulation_hf[2]\n",
    "                worksheet['F{}'.format(str(counter+1))] = noise_simulation_tv[2]\n",
    "                worksheet['G{}'.format(str(counter))] = noise_simulation_hf[3]\n",
    "                worksheet['G{}'.format(str(counter+1))] = noise_simulation_tv[3]\n",
    "                worksheet['H{}'.format(str(counter))] = noise_simulation_hf[4]\n",
    "                worksheet['H{}'.format(str(counter+1))] = noise_simulation_tv[4]\n",
    "                worksheet['I{}'.format(str(counter))] = zne_hf\n",
    "                worksheet['I{}'.format(str(counter+1))] = zne_tv\n",
    "                worksheet['J{}'.format(str(counter))] = ffzne_hf\n",
    "                worksheet['J{}'.format(str(counter+1))] = ffzne_tv\n",
    "                worksheet['K{}'.format(str(counter))] = rbzne_hf\n",
    "                worksheet['K{}'.format(str(counter+1))] = rbzne_tv\n",
    "\n",
    "                worksheet['A{}'.format(str(counter+2))] = 'Circuit reliabilities'\n",
    "                worksheet['D{}'.format(str(counter+2))] = reliabilities[0]\n",
    "                worksheet['E{}'.format(str(counter+2))] = reliabilities[1]\n",
    "                worksheet['F{}'.format(str(counter+2))] = reliabilities[2]\n",
    "                worksheet['G{}'.format(str(counter+2))] = reliabilities[3]\n",
    "                worksheet['H{}'.format(str(counter+2))] = reliabilities[4]\n",
    "\n",
    "                worksheet['A{}'.format(str(counter+3))] = 'Circuit depth'\n",
    "                worksheet['D{}'.format(str(counter+3))] = circuits[0].depth()\n",
    "                worksheet['E{}'.format(str(counter+3))] = circuits[1].depth()\n",
    "                worksheet['F{}'.format(str(counter+3))] = circuits[2].depth()\n",
    "                worksheet['G{}'.format(str(counter+3))] = circuits[3].depth()\n",
    "                worksheet['H{}'.format(str(counter+3))] = circuits[4].depth()\n",
    "\n",
    "                worksheet['A{}'.format(str(counter+4))] = 'RZX count'\n",
    "                worksheet['D{}'.format(str(counter+4))] = circuits[0].count_ops()['rzx']\n",
    "                worksheet['E{}'.format(str(counter+4))] = circuits[1].count_ops()['rzx']\n",
    "                worksheet['F{}'.format(str(counter+4))] = circuits[2].count_ops()['rzx']\n",
    "                worksheet['G{}'.format(str(counter+4))] = circuits[3].count_ops()['rzx']\n",
    "                worksheet['H{}'.format(str(counter+4))] = circuits[4].count_ops()['rzx']\n",
    "\n",
    "                worksheet['A{}'.format(str(counter+5))] = 'RX count'\n",
    "                worksheet['D{}'.format(str(counter+5))] = circuits[0].count_ops()['rx']\n",
    "                worksheet['E{}'.format(str(counter+5))] = circuits[1].count_ops()['rx']\n",
    "                worksheet['F{}'.format(str(counter+5))] = circuits[2].count_ops()['rx']\n",
    "                worksheet['G{}'.format(str(counter+5))] = circuits[3].count_ops()['rx']\n",
    "                worksheet['H{}'.format(str(counter+5))] = circuits[4].count_ops()['rx']\n",
    "\n",
    "                #Create a border around A19 to J21\n",
    "                border = Border(left=Side(border_style='thin', color='FF000000'),\n",
    "                                right=Side(border_style='thin', color='FF000000'),\n",
    "                                top=Side(border_style='thin', color='FF000000'),\n",
    "                                bottom=Side(border_style='thin', color='FF000000'))\n",
    "                \n",
    "                left_thick_border = Border(left=Side(border_style='medium', color='FF000000'))\n",
    "                bottom_thick_border = Border(bottom=Side(border_style='medium', color='FF000000'))\n",
    "                right_thick_border = Border(right=Side(border_style='medium', color='FF000000'))\n",
    "\n",
    "                heading_border = Border(left=Side(border_style='medium', color='FF000000'),\n",
    "                                        right=Side(border_style='medium', color='FF000000'),\n",
    "                                        top=Side(border_style='medium', color='FF000000'),\n",
    "                                        bottom=Side(border_style='medium', color='FF000000'))\n",
    "                \n",
    "                bottom_right_thick_border = Border(right=Side(border_style='medium', color='FF000000'),\n",
    "                                                    bottom=Side(border_style='medium', color='FF000000'))\n",
    "\n",
    "                for row in worksheet.iter_rows(min_row=1, max_row=counter-2, min_col=1, max_col=1):\n",
    "                    for cell in row:\n",
    "                        cell.border = left_thick_border\n",
    "\n",
    "                for row in worksheet.iter_rows(min_row=1, max_row=counter-2, min_col=11, max_col=11):\n",
    "                    for cell in row:\n",
    "                        cell.border = right_thick_border\n",
    "\n",
    "                for row in worksheet.iter_rows(min_row=counter-2, max_row=counter-2, min_col=1, max_col=11):\n",
    "                    for cell in row:\n",
    "                        cell.border = bottom_thick_border\n",
    "                \n",
    "                for row in worksheet.iter_rows(min_row=counter, max_row=counter+5, min_col=1, max_col=11):\n",
    "                    for cell in row:\n",
    "                        cell.border = border\n",
    "\n",
    "                for row in worksheet.iter_rows(min_row=1, max_row=1, min_col=1, max_col=11):\n",
    "                    for cell in row:\n",
    "                        cell.border = heading_border\n",
    "\n",
    "                #assign bottom right thick border to J19\n",
    "                worksheet['K{}'.format(str(counter-2))].border = bottom_right_thick_border\n",
    "\n",
    "                # Auto-adjusting column widths\n",
    "                for column_cells in worksheet.columns:\n",
    "                    length = max(len(str(cell.value)) for cell in column_cells)\n",
    "                    worksheet.column_dimensions[column_cells[0].column_letter].width = length\n",
    "\n",
    "                # Centering text in every cell\n",
    "                for row in worksheet.iter_rows():\n",
    "                    for cell in row:\n",
    "                        cell.alignment = Alignment(horizontal='center', vertical='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(summary_dict_list)\n",
    "summary_df['ZNE HF % change'] = ((summary_df['ZNE HF'] - summary_df['Noise HF']) / summary_df['Noise HF']) * 100\n",
    "summary_df['ZNE TV % change'] = ((summary_df['Noise TV'] - summary_df['ZNE TV']) / summary_df['Noise TV']) * 100\n",
    "summary_df['FFZNE HF % change'] = ((summary_df['FFZNE HF'] - summary_df['Noise HF']) / summary_df['Noise HF']) * 100\n",
    "summary_df['FFZNE TV % change'] = ((summary_df['Noise TV'] - summary_df['FFZNE TV']) / summary_df['Noise TV']) * 100\n",
    "summary_df['RBZNE HF % change'] = ((summary_df['RBZNE HF'] - summary_df['Noise HF']) / summary_df['Noise HF']) * 100\n",
    "summary_df['RBZNE TV % change'] = ((summary_df['Noise TV'] - summary_df['RBZNE TV']) / summary_df['Noise TV']) * 100\n",
    "\n",
    "#Arrange the columns\n",
    "summary_df = summary_df[['N', 'T', 'System', \n",
    "                         'Without Noise HF', 'Noise HF', \n",
    "                            'ZNE HF', 'ZNE HF % change',\n",
    "                            'FFZNE HF', 'FFZNE HF % change',\n",
    "                            'RBZNE HF', 'RBZNE HF % change',\n",
    "                            'Without Noise TV', 'Noise TV',\n",
    "                            'ZNE TV', 'ZNE TV % change',\n",
    "                            'FFZNE TV', 'FFZNE TV % change',\n",
    "                            'RBZNE TV', 'RBZNE TV % change']]\n",
    "\n",
    "#Sort these records by System, N and T\n",
    "summary_df = summary_df.sort_values(by=['System', 'N', 'T'])\n",
    "\n",
    "with pd.ExcelWriter(\"results/summary_distribution_data.xlsx\".format(system), engine='openpyxl') as writer:\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Summary']\n",
    "    \n",
    "    # Accessing the active sheet\n",
    "    active_sheet = workbook.active\n",
    "\n",
    "    # Calculate Geometric mean of 1 + (% change / 100) for Hellinger fidelity and TV\n",
    "    worksheet['A213'] = 'Geometric mean'\n",
    "    worksheet['G213'] = (1 + summary_df['ZNE HF % change'] / 100).prod() ** (1 / len(summary_df))\n",
    "    worksheet['O213'] = (1 + summary_df['ZNE TV % change'] / 100).prod() ** (1 / len(summary_df))\n",
    "    worksheet['I213'] = (1 + summary_df['FFZNE HF % change'] / 100).prod() ** (1 / len(summary_df))\n",
    "    worksheet['Q213'] = (1 + summary_df['FFZNE TV % change'] / 100).prod() ** (1 / len(summary_df))\n",
    "    worksheet['K213'] = (1 + summary_df['RBZNE HF % change'] / 100).prod() ** (1 / len(summary_df))\n",
    "    worksheet['S213'] = (1 + summary_df['RBZNE TV % change'] / 100).prod() ** (1 / len(summary_df))\n",
    "\n",
    "    #Calculate Geometric mean of 1 + (% change / 100) for Hellinger fidelity and TV for each systems\n",
    "    worksheet['A214'] = 'Geometric mean for ibm_kyoto'\n",
    "    worksheet['G214'] = (1 + summary_df[summary_df['System'] == 'ibm_kyoto']['ZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_kyoto']))\n",
    "    worksheet['O214'] = (1 + summary_df[summary_df['System'] == 'ibm_kyoto']['ZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_kyoto']))\n",
    "    worksheet['I214'] = (1 + summary_df[summary_df['System'] == 'ibm_kyoto']['FFZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_kyoto']))\n",
    "    worksheet['Q214'] = (1 + summary_df[summary_df['System'] == 'ibm_kyoto']['FFZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_kyoto']))\n",
    "    worksheet['K214'] = (1 + summary_df[summary_df['System'] == 'ibm_kyoto']['RBZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_kyoto']))\n",
    "    worksheet['S214'] = (1 + summary_df[summary_df['System'] == 'ibm_kyoto']['RBZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_kyoto']))\n",
    "\n",
    "    worksheet['A215'] = 'Geometric mean for ibm_sherbrooke'\n",
    "    worksheet['G215'] = (1 + summary_df[summary_df['System'] == 'ibm_sherbrooke']['ZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_sherbrooke']))\n",
    "    worksheet['O215'] = (1 + summary_df[summary_df['System'] == 'ibm_sherbrooke']['ZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_sherbrooke']))\n",
    "    worksheet['I215'] = (1 + summary_df[summary_df['System'] == 'ibm_sherbrooke']['FFZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_sherbrooke']))\n",
    "    worksheet['Q215'] = (1 + summary_df[summary_df['System'] == 'ibm_sherbrooke']['FFZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_sherbrooke']))\n",
    "    worksheet['K215'] = (1 + summary_df[summary_df['System'] == 'ibm_sherbrooke']['RBZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_sherbrooke']))\n",
    "    worksheet['S215'] = (1 + summary_df[summary_df['System'] == 'ibm_sherbrooke']['RBZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_sherbrooke']))\n",
    "\n",
    "    worksheet['A216'] = 'Geometric mean for ibm_nazca'\n",
    "    worksheet['G216'] = (1 + summary_df[summary_df['System'] == 'ibm_nazca']['ZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_nazca']))\n",
    "    worksheet['O216'] = (1 + summary_df[summary_df['System'] == 'ibm_nazca']['ZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_nazca']))\n",
    "    worksheet['I216'] = (1 + summary_df[summary_df['System'] == 'ibm_nazca']['FFZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_nazca']))\n",
    "    worksheet['Q216'] = (1 + summary_df[summary_df['System'] == 'ibm_nazca']['FFZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_nazca']))\n",
    "    worksheet['K216'] = (1 + summary_df[summary_df['System'] == 'ibm_nazca']['RBZNE HF % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_nazca']))\n",
    "    worksheet['S216'] = (1 + summary_df[summary_df['System'] == 'ibm_nazca']['RBZNE TV % change'] / 100).prod() ** (1 / len(summary_df[summary_df['System'] == 'ibm_nazca']))\n",
    "\n",
    "    # Auto-adjusting column widths\n",
    "    for column_cells in worksheet.columns:\n",
    "        length = max(len(str(cell.value)) for cell in column_cells)\n",
    "        worksheet.column_dimensions[column_cells[0].column_letter].width = length\n",
    "\n",
    "    # Centering text in every cell\n",
    "    for row in worksheet.iter_rows():\n",
    "        for cell in row:\n",
    "            cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9929843469726516,\n",
       " 0.9929843469726516,\n",
       " 0.9929843469726516,\n",
       " 0.9929843469726516,\n",
       " 0.9929843469726516]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: hellinger_fidelity(x, ideal_result), without_noise_simulation_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9677234582092556,\n",
       " 0.9309184744481795,\n",
       " 0.9044210928651266,\n",
       " 0.8772649230512174,\n",
       " 0.8564561388984665]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: hellinger_fidelity(x, ideal_result), noise_simulation_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model with 4 qubits and simulation time to be: 3 units\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from hamiltonian_models import Ising\n",
    "\n",
    "N = 4\n",
    "T = 3\n",
    "\n",
    "h = np.array([1 for j in range(N)])\n",
    "J_chain = np.zeros((N, N))\n",
    "for j in range(N - 1):\n",
    "    J_chain[j, j + 1] = 1\n",
    "\n",
    "J_cycle = np.copy(J_chain)\n",
    "J_cycle[0, N - 1] = 1\n",
    "\n",
    "#On the IBM devices, only Ising_chain has a solution, therefore keeping it\n",
    "print(\"Creating the model with {} qubits and simulation time to be: {} units\".format(N,T))\n",
    "Ising_chain = Ising(N, T, J_chain, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_provider_custom import IBMProvider as IBMProviderCustom\n",
    "ibm = IBMProviderCustom(from_file=\"../ibm_API_key\", hub=\"ibm-q-ncsu\", group=\"nc-state\", project=\"quantum-compiler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "ibm.compile(Ising_chain, backend=system, trotter_num=4,use_pulse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = ibm.prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit[0].draw(output='mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the backend\n",
    "backend = provider.get_backend('ibm_brisbane')\n",
    "\n",
    "circ = circuit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_result = ideal_results[N,T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model = NoiseModel.from_backend(backend)\n",
    "\n",
    "# Get the rzx errors\n",
    "with open('error_rates.pkl', 'rb') as f:\n",
    "    error_rates = pickle.load(f)\n",
    "\n",
    "# Add rzx errors\n",
    "for qubit, error in error_rates[system]['rzx'].items():\n",
    "    noise_model.add_quantum_error(noise.depolarizing_error(error,2),\"rzx\",list(qubit))\n",
    "\n",
    "# Add rx errors\n",
    "for qubit, error in error_rates[system]['rx'].items():\n",
    "    noise_model.add_quantum_error(noise.depolarizing_error(error,1),\"rx\",[qubit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9680807730817306"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simulator for backend\n",
    "basis_gates = noise_model.basis_gates\n",
    "coupling_map = backend.configuration().coupling_map\n",
    "\n",
    "sim = AerSimulator(noise_model=noise_model,\n",
    "                   basis_gates=basis_gates,\n",
    "                   coupling_map=coupling_map)\n",
    "\n",
    "# simulate and extract results\n",
    "simulator_result = sim.run(circ, shots = 4096, seed_simulator=12345).result()\n",
    "simulator_counts = simulator_result.get_counts()\n",
    "\n",
    "#Reverse the key string\n",
    "simulator_counts = {k[::-1]: v/4096 for k, v in simulator_counts.items()}\n",
    "\n",
    "#Calculate hellinger fidelity\n",
    "from qiskit.quantum_info import hellinger_fidelity\n",
    "hellinger_fidelity(ideal_result, simulator_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Noise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.985270406474338"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simulator for backend\n",
    "noise_model = NoiseModel.from_backend(backend)\n",
    "basis_gates = noise_model.basis_gates\n",
    "coupling_map = backend.configuration().coupling_map\n",
    "\n",
    "sim = AerSimulator(noise_model=noise_model,\n",
    "                   basis_gates=basis_gates,\n",
    "                   coupling_map=coupling_map)\n",
    "\n",
    "# simulate and extract results\n",
    "simulator_result = sim.run(circ, shots = 4096, seed_simulator=12345).result()\n",
    "simulator_counts = simulator_result.get_counts()\n",
    "\n",
    "#Reverse the key string\n",
    "simulator_counts = {k[::-1]: v/4096 for k, v in simulator_counts.items()}\n",
    "\n",
    "#Calculate hellinger fidelity\n",
    "from qiskit.quantum_info import hellinger_fidelity\n",
    "hellinger_fidelity(ideal_result, simulator_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without noise simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35439788695954233"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simulator for backend\n",
    "sim = AerSimulator()\n",
    "\n",
    "# simulate and extract results\n",
    "simulator_result = sim.run(circ, shots = 4096, seed_simulator=12345).result()\n",
    "simulator_counts = simulator_result.get_counts()\n",
    "\n",
    "#Reverse the key string\n",
    "simulator_counts = {k[::-1]: v/4096 for k, v in simulator_counts.items()}\n",
    "\n",
    "#Calculate hellinger fidelity\n",
    "from qiskit.quantum_info import hellinger_fidelity\n",
    "hellinger_fidelity(ideal_result, simulator_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simuq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
